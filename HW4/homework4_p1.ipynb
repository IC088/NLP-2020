{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ok9xpaI-uyUT"
   },
   "source": [
    "![sutd](sutd.png)\n",
    "## <center>50.040 Natural Language Processing, Summer 2020<center>\n",
    "<center>**Homework 4**\n",
    "\n",
    "<center>**Due 31 July 2020, 5pm** <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHLjIQokuyUV"
   },
   "source": [
    "**Write your student ID and name**\n",
    "\n",
    "ID: 1003056\n",
    "\n",
    "Name: Ivan Christian\n",
    "\n",
    "Students whom you have discussed with (if any): Ng Jen Yang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F7rJYYMnuyUW"
   },
   "source": [
    "### Requirements:\n",
    "- Use Python to complete this homework.\n",
    "- Please list students with whom you have discussed (if any).\n",
    "- Follow the honor code strictly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "joGu6trB8RRN"
   },
   "source": [
    "In this homework, we'll implement ``IBM Model 1`` using the ``expectation–maximization (EM)`` algorithm. We need to estimate the  translation probabilities  $t(f|e)$ on a parallel corpus, where $e$ is a word from the English sentences and $f$ is a word from the corresponding foreign sentences. \n",
    "\n",
    "Note that there's a constraint for such probabilities:\n",
    "$$\\sum_f t(f|e)=1 , \\ \\ \\  t(f|e) \\ge 0  \\quad (1)$$\n",
    "\n",
    "**We'll use this constraint when initializing the translation probabilities in subsequent tasks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stJOvS_A8RRO"
   },
   "source": [
    "## Data\n",
    "We'll use the English-French parallel corpus under the folder ``data/part1``, which contains a set of translation instances. As can be seen below each instance consists of an English-French sentence pair (note that we are translating from French into English, but as we discussed in class, when working on the translation model using IBM model 1, we are interested in generating French from English).\n",
    "\n",
    "\n",
    "\n",
    "    Hop in.\tMontez.\n",
    "    Hug me.\tSerre-moi dans tes bras !\n",
    "    I left.\tJe suis parti.\n",
    "\n",
    "The dataset is obtained from [MXNET](http://data.mxnet.io/data/fra-eng.zip). Please run the provided code below to obtain the preprocessed English sentences and French sentences. Do not perform any further preprocessing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from time import time\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Statistical Machine Translation \\[25 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soTtZXt68RRT"
   },
   "outputs": [],
   "source": [
    "path = 'data/part1/en-fr.txt'\n",
    "with open(path, 'r', encoding='utf8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "#Original code from \n",
    "#https://www.d2l.ai/chapter_recurrent-neural-networks\n",
    "def preprocess_nmt(text):\n",
    "    '''\n",
    "    Arg:\n",
    "        text: parallel text, string\n",
    "    Return:\n",
    "        out: preprocessed text, string\n",
    "    '''\n",
    "    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n",
    "    no_space = lambda char, prev_char: (\n",
    "        True if char in (',', '!', '.') and prev_char != ' ' else False)\n",
    "    out = [' '+char if i > 0 and no_space(char, text[i-1]) else char\n",
    "           for i, char in enumerate(text.lower())]\n",
    "    out = ''.join(out)\n",
    "    return out\n",
    "\n",
    "def tokenize_nmt(text, num_examples = None):\n",
    "    '''\n",
    "    Args:\n",
    "        text: parallel text, string\n",
    "        num_examples: number of examples to be selected, int\n",
    "    Returns:\n",
    "        left: English sentences, list\n",
    "        right: French sentences, list\n",
    "    '''\n",
    "    left, right = [], []\n",
    "    for i, line in enumerate(text.split('\\n')):\n",
    "        if num_examples and i > num_examples: break\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) == 2:\n",
    "            left.append(parts[0].split(' '))\n",
    "            right.append(parts[1].split(' '))\n",
    "    return left, right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOUt-g3B8RRV"
   },
   "outputs": [],
   "source": [
    "#English sentences and corresponding French sentences\n",
    "#Each sentence has been preprocessed and tokenized\n",
    "text = preprocess_nmt(raw_text)\n",
    "english_sents, french_sents = tokenize_nmt(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['go', '.'],\n",
       "  ['hi', '.'],\n",
       "  ['run', '!'],\n",
       "  ['run', '!'],\n",
       "  ['who?'],\n",
       "  ['wow', '!'],\n",
       "  ['fire', '!'],\n",
       "  ['help', '!'],\n",
       "  ['jump', '.'],\n",
       "  ['stop', '!']],\n",
       " [['va', '!'],\n",
       "  ['salut', '!'],\n",
       "  ['cours', '!'],\n",
       "  ['courez', '!'],\n",
       "  ['qui', '?'],\n",
       "  ['ça', 'alors', '!'],\n",
       "  ['au', 'feu', '!'],\n",
       "  ['à', \"l'aide\", '!'],\n",
       "  ['saute', '.'],\n",
       "  ['ça', 'suffit', '!']])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sents[:10], french_sents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCTLIntg8RRX"
   },
   "source": [
    "\n",
    "### Quesiton 1 (3 points)\n",
    "1. Implement ``word_pairs_in_corpus`` which finds out all the possible word pairs (alignments) $(e, f)$ that appear in all the instances of the English-French dataset ``english_sents``, ``french_sents``. Note that we need to pad each English sentence with the special token \"NULL\" at the beginning.\n",
    "2. List down the 10 most frequent pairs. \n",
    "3. Count the number of unique pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_pairs_in_corpus(en_sents, fr_sents):\n",
    "    '''\n",
    "    params:\n",
    "        en_sents: list[list[str]]\n",
    "        fr_sents: list[list[str]]\n",
    "    return:\n",
    "        align_counts: Dict()--- key: (english_word, french_word), value: counts of the word pair in the corpus\n",
    "    '''\n",
    "    align_counts = None\n",
    "    # YOUR CODE HERE\n",
    "    align_counts = defaultdict()\n",
    "#     print(len(en_sents), len(fr_sents))\n",
    "    \n",
    "    sents_len = len(en_sents)\n",
    "    for idx in range(sents_len):            \n",
    "        \n",
    "        for en_word in en_sents[idx]:\n",
    "            for fr_word in fr_sents[idx]:\n",
    "                if (en_word, fr_word) in align_counts:\n",
    "                    align_counts[(en_word, fr_word)] += 1\n",
    "                else:\n",
    "                    align_counts[(en_word, fr_word)] = 1\n",
    "    # END OF YOUR CODE\n",
    "    return Counter(align_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(('.', '.'), 136734),\n",
       "  (('NULL', '.'), 135221),\n",
       "  (('i', '.'), 43189),\n",
       "  (('NULL', 'je'), 39821),\n",
       "  (('.', 'je'), 39096),\n",
       "  (('NULL', 'de'), 35073),\n",
       "  (('i', 'je'), 34415),\n",
       "  (('to', '.'), 31647),\n",
       "  (('.', 'de'), 30490),\n",
       "  (('the', '.'), 29170)],\n",
       " 1402126)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sents = [['NULL'] + sent for sent in english_sents]\n",
    "align_counts = word_pairs_in_corpus(english_sents, french_sents)\n",
    "align_counts.most_common(10), len(align_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = set([item[0] for item in align_counts.keys()])\n",
    "fr_vocab = set([item[1] for item in align_counts.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17430, 29741)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab), len(fr_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (2 points):\n",
    "\n",
    "Implment the ``corpus_log_prob `` that computes the log probability of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_log_prob(en_sents, fr_sents, t):\n",
    "    '''\n",
    "    params:\n",
    "        en_sents: list[list[str]]\n",
    "        fr_sents: list[list[str]]\n",
    "        t: Dict() --- contains translation probabilities. For example, t[(english_word, french_word)] = p\n",
    "    return:\n",
    "        logp: float --- log probability of the corpus\n",
    "    '''\n",
    "    logp = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    for en_sent, fr_sent in zip(en_sents, fr_sents):\n",
    "        for en_word in en_sent:\n",
    "            for fr_word in fr_sent:\n",
    "                p = t[(en_word, fr_word)]\n",
    "                t[(en_word, fr_word)] = np.log(p)\n",
    "                \n",
    "                logp += t[(en_word, fr_word)]\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    return logp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "424sQt3b8RRZ"
   },
   "source": [
    "## Hard EM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WB_5EV3q8RRa"
   },
   "source": [
    "### Question 3 (10 points)\n",
    "Based on the word pairs obtained in Q1, implement ``Hard EM algorithm`` to calculate the  translation probabilities  $t(f|e)$ on the English-French corpus. \n",
    "\n",
    "It is possible that in the hard EM algorithm a word $\\tilde{e}$ from an English sentence may not be aligned with any word from the corresponding French sentence. In this case, let us set the corresponding probabilities $t(f|\\tilde{e})=\\frac{1}{|V_f|}$ where $|V_f|$ is the size of the French vocabulary (in this case, the number of unique French words that ever appear in the training parallel corpus).\n",
    "\n",
    "1. Implement ``init`` function which initializes the translation probability dictionary $t$ according to equation (1). You need to use ``numpy.random.rand()`` in this part.\n",
    "2. Implement ``hard_EM`` function which runs one ``Expectation/Maximization`` iteration.\n",
    "3. Run the training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(word_pairs):\n",
    "    '''\n",
    "    Use np.random.rand() to initialize translation probabilities t(f|e)\n",
    "    params:\n",
    "        word_pairs: List[(str, str)] --- list of word pairs\n",
    "    return:\n",
    "        t: Dict(), key: (english_word, french_word), value: the initial probability t(f|e). For example, t[(a, un)] = 0.5\n",
    "    '''\n",
    "    np.random.seed(5)\n",
    "    t = dict()\n",
    "    ### YOUR CODE HERE\n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    for en_word, fr_word in word_pairs:\n",
    "        t[(en_word, fr_word)] = np.random.rand()\n",
    "#     for en_word, _ in tqdm(word_pairs):\n",
    "#         list_p = []\n",
    "#         en_key_pairs = [wordpair for wordpair in t.keys() if wordpair[0] == en_word]\n",
    "#         align_pair_counts = [t[wordpair] for wordpair in t.keys() if wordpair[0] == en_word]\n",
    "#         # Get the sum for all the en_word count in the dict\n",
    "#         align_pair_sum = sum(align_pair_counts)\n",
    "        \n",
    "#         for p_val in align_pair_counts:\n",
    "#             init_p = p_val / align_pair_sum\n",
    "#             list_p.append(init_p)\n",
    "#         adjusted_val = zip(en_key_pairs, list_p)\n",
    "        \n",
    "#         for key , val in adjusted_val:\n",
    "#             t[key] = val\n",
    "\n",
    "        \n",
    "    ### END OF YOUR CODE\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('NULL', 'va'): 0.22199317108973948,\n",
       " ('NULL', '!'): 0.8707323061773764,\n",
       " ('go', 'va'): 0.20671915533942642,\n",
       " ('go', '!'): 0.9186109079379216,\n",
       " ('.', 'va'): 0.48841118879482914,\n",
       " ('.', '!'): 0.6117438629026457,\n",
       " ('NULL', 'salut'): 0.7659078564803156,\n",
       " ('hi', 'salut'): 0.5184179878729432,\n",
       " ('hi', '!'): 0.29680050157622195,\n",
       " ('.', 'salut'): 0.18772122866125163,\n",
       " ('NULL', 'cours'): 0.08074126876487486,\n",
       " ('run', 'cours'): 0.73844029619897,\n",
       " ('run', '!'): 0.4413092228959531,\n",
       " ('!', 'cours'): 0.1583098677126512,\n",
       " ('!', '!'): 0.8799370312012789,\n",
       " ('NULL', 'courez'): 0.27408646199222464,\n",
       " ('run', 'courez'): 0.4142350190810513,\n",
       " ('!', 'courez'): 0.29607993273364797,\n",
       " ('NULL', 'qui'): 0.6287879088794833,\n",
       " ('NULL', '?'): 0.579837810189545,\n",
       " ('who?', 'qui'): 0.5999291966249876,\n",
       " ('who?', '?'): 0.26581911753550724,\n",
       " ('NULL', 'ça'): 0.2846858806413638,\n",
       " ('NULL', 'alors'): 0.2535882057737875,\n",
       " ('wow', 'ça'): 0.3275639476887341,\n",
       " ('wow', 'alors'): 0.14416430065342045,\n",
       " ('wow', '!'): 0.1656128612012676,\n",
       " ('!', 'ça'): 0.9639305290679419,\n",
       " ('!', 'alors'): 0.9602267152856938,\n",
       " ('NULL', 'au'): 0.18841465559593518,\n",
       " ('NULL', 'feu'): 0.024306561629486967,\n",
       " ('fire', 'au'): 0.20455554637995066,\n",
       " ('fire', 'feu'): 0.6998436141265575,\n",
       " ('fire', '!'): 0.7795145855555298,\n",
       " ('!', 'au'): 0.02293309243908148,\n",
       " ('!', 'feu'): 0.577662858129756,\n",
       " ('NULL', 'à'): 0.001642172716045276,\n",
       " ('NULL', \"l'aide\"): 0.5154726119053935,\n",
       " ('help', 'à'): 0.6397951761308571,\n",
       " ('help', \"l'aide\"): 0.9856244028041888,\n",
       " ('help', '!'): 0.25909759641110575,\n",
       " ('!', 'à'): 0.8024968852628702,\n",
       " ('!', \"l'aide\"): 0.8704830870014831,\n",
       " ('NULL', 'saute'): 0.9227496139456699,\n",
       " ('NULL', '.'): 0.0022142125324435824,\n",
       " ('jump', 'saute'): 0.4694883717575773,\n",
       " ('jump', '.'): 0.9814687376060105,\n",
       " ('.', 'saute'): 0.3989448039028505,\n",
       " ('.', '.'): 0.8137324775869181,\n",
       " ('NULL', 'suffit'): 0.5464564979724778,\n",
       " ('stop', 'ça'): 0.7708540871402245,\n",
       " ('stop', 'suffit'): 0.484931074988458,\n",
       " ('stop', '!'): 0.029111563672717722,\n",
       " ('!', 'suffit'): 0.08652568840220509,\n",
       " ('NULL', 'stop'): 0.11145381237802332,\n",
       " ('stop', 'stop'): 0.25124511169054764,\n",
       " ('!', 'stop'): 0.964915292526365,\n",
       " ('NULL', 'arrête-toi'): 0.6317660527377454,\n",
       " ('stop', 'arrête-toi'): 0.8166602026153619,\n",
       " ('!', 'arrête-toi'): 0.5660819960927563,\n",
       " ('NULL', 'attends'): 0.6353562055818931,\n",
       " ('wait', 'attends'): 0.8119023911804106,\n",
       " ('wait', '!'): 0.9266826152438743,\n",
       " ('!', 'attends'): 0.9126267637037832,\n",
       " ('NULL', 'attendez'): 0.8248107204385254,\n",
       " ('wait', 'attendez'): 0.09420273217732267,\n",
       " ('!', 'attendez'): 0.3610484184638091,\n",
       " ('NULL', 'poursuis'): 0.03550903176033027,\n",
       " ('go', 'poursuis'): 0.5463583485408069,\n",
       " ('go', '.'): 0.7961427208560042,\n",
       " ('on', 'poursuis'): 0.05114280310134711,\n",
       " ('on', '.'): 0.18866773579310792,\n",
       " ('.', 'poursuis'): 0.3654777679121648,\n",
       " ('NULL', 'continuez'): 0.24429086695790836,\n",
       " ('go', 'continuez'): 0.795087472921032,\n",
       " ('on', 'continuez'): 0.3520949357663685,\n",
       " ('.', 'continuez'): 0.6388776820603653,\n",
       " ('NULL', 'poursuivez'): 0.4934150518967597,\n",
       " ('go', 'poursuivez'): 0.5834997437200565,\n",
       " ('on', 'poursuivez'): 0.9392993519648516,\n",
       " ('.', 'poursuivez'): 0.9435400820158796,\n",
       " ('NULL', 'bonjour'): 0.11169242718357142,\n",
       " ('hello', 'bonjour'): 0.8435549661102237,\n",
       " ('hello', '!'): 0.34602815175595236,\n",
       " ('!', 'bonjour'): 0.10082727286264515,\n",
       " ('hello', 'salut'): 0.3834090660671152,\n",
       " ('!', 'salut'): 0.5103547973392479,\n",
       " ('NULL', 'je'): 0.9611030819651298,\n",
       " ('NULL', 'comprends'): 0.3715126153280073,\n",
       " ('i', 'je'): 0.01236941160035765,\n",
       " ('i', 'comprends'): 0.8597068869881915,\n",
       " ('i', '.'): 0.11111074954036526,\n",
       " ('see', 'je'): 0.47833904398678495,\n",
       " ('see', 'comprends'): 0.8499800323861936,\n",
       " ('see', '.'): 0.5147379670006791,\n",
       " ('.', 'je'): 0.44660782792231324,\n",
       " ('.', 'comprends'): 0.8004764207505697,\n",
       " ('NULL', \"j'essaye\"): 0.020391378448150643,\n",
       " ('i', \"j'essaye\"): 0.5726186488077992,\n",
       " ('try', \"j'essaye\"): 0.41138361577937654,\n",
       " ('try', '.'): 0.9851367976958045,\n",
       " ('.', \"j'essaye\"): 0.8014015304110701,\n",
       " ('NULL', \"j'ai\"): 0.05396210214514685,\n",
       " ('NULL', 'gagné'): 0.19047777345550265,\n",
       " ('i', \"j'ai\"): 0.45241884581697545,\n",
       " ('i', 'gagné'): 0.7029420771179782,\n",
       " ('i', '!'): 0.3320481495356774,\n",
       " ('won', \"j'ai\"): 0.3599831951713076,\n",
       " ('won', 'gagné'): 0.921470565959177,\n",
       " ('won', '!'): 0.9536305057273471,\n",
       " ('!', \"j'ai\"): 0.4076857286771436,\n",
       " ('!', 'gagné'): 0.8985711548847233,\n",
       " ('NULL', \"l'ai\"): 0.3302532519595063,\n",
       " ('NULL', 'emporté'): 0.08273856907998767,\n",
       " ('i', \"l'ai\"): 0.5267175654585914,\n",
       " ('i', 'emporté'): 0.6608443909583853,\n",
       " ('won', 'je'): 0.8929842943552984,\n",
       " ('won', \"l'ai\"): 0.9651575470143406,\n",
       " ('won', 'emporté'): 0.7699326768913147,\n",
       " ('!', 'je'): 0.759099118289326,\n",
       " ('!', \"l'ai\"): 0.7100490473544384,\n",
       " ('!', 'emporté'): 0.7015528325813724,\n",
       " ('NULL', 'j’ai'): 0.7673313811177834,\n",
       " ('i', 'j’ai'): 0.9743494788856439,\n",
       " ('won', 'j’ai'): 0.3737145173959693,\n",
       " ('won', '.'): 0.08305444303844489,\n",
       " ('.', 'j’ai'): 0.23964043961222492,\n",
       " ('.', 'gagné'): 0.22148276004299516,\n",
       " ('NULL', 'oh'): 0.36359979680410603,\n",
       " ('NULL', 'non'): 0.8103142321123518,\n",
       " ('oh', 'oh'): 0.0600961698663498,\n",
       " ('oh', 'non'): 0.44974355789655607,\n",
       " ('oh', '!'): 0.813170527483345,\n",
       " ('no', 'oh'): 0.2642383745406488,\n",
       " ('no', 'non'): 0.06340098197336863,\n",
       " ('no', '!'): 0.24210767225593488,\n",
       " ('!', 'oh'): 0.0850704617502156,\n",
       " ('!', 'non'): 0.807777435347352,\n",
       " ('NULL', 'attaque'): 0.17025007563808214,\n",
       " ('attack', 'attaque'): 0.1953446255624387,\n",
       " ('attack', '!'): 0.8146420115578603,\n",
       " ('!', 'attaque'): 0.8102855291824956,\n",
       " ('NULL', 'attaquez'): 0.5893738782337425,\n",
       " ('attack', 'attaquez'): 0.914734340117462,\n",
       " ('!', 'attaquez'): 0.05982163675463459,\n",
       " ('NULL', 'santé'): 0.9649966402703323,\n",
       " ('cheers', 'santé'): 0.5709752168558058,\n",
       " ('cheers', '!'): 0.3025181125003943,\n",
       " ('!', 'santé'): 0.8257058264983507,\n",
       " ('NULL', 'votre'): 0.6594172803533213,\n",
       " ('cheers', 'à'): 0.9865014414033959,\n",
       " ('cheers', 'votre'): 0.10748953357509894,\n",
       " ('!', 'votre'): 0.5809185276333954,\n",
       " ('NULL', 'merci'): 0.4728281550572868,\n",
       " ('cheers', 'merci'): 0.6522707859877006,\n",
       " ('!', 'merci'): 0.24185905409742914,\n",
       " ('NULL', 'tchin-tchin'): 0.031130063418406073,\n",
       " ('cheers', 'tchin-tchin'): 0.5442323527461858,\n",
       " ('!', 'tchin-tchin'): 0.364710178792385,\n",
       " ('NULL', 'lève-toi'): 0.8923332752985107,\n",
       " ('get', 'lève-toi'): 0.4593455947586442,\n",
       " ('get', '.'): 0.4186541000368995,\n",
       " ('up', 'lève-toi'): 0.6329055407909672,\n",
       " ('up', '.'): 0.5271788329465622,\n",
       " ('.', 'lève-toi'): 0.9612111401741152,\n",
       " ('NULL', ','): 0.7890101145562437,\n",
       " ('NULL', 'maintenant'): 0.4966955091225945,\n",
       " ('go', ','): 0.21114100089423782,\n",
       " ('go', 'maintenant'): 0.6039841410962836,\n",
       " ('now', 'va'): 0.7485758105548178,\n",
       " ('now', ','): 0.7558638312606142,\n",
       " ('now', 'maintenant'): 0.9935040079326672,\n",
       " ('now', '.'): 0.2184977813400989,\n",
       " ('.', ','): 0.4256373335349867,\n",
       " ('.', 'maintenant'): 0.42384960280522266,\n",
       " ('NULL', 'allez-y'): 0.31864643768233136,\n",
       " ('go', 'allez-y'): 0.36533301893440306,\n",
       " ('now', 'allez-y'): 0.4779413101045564,\n",
       " ('.', 'allez-y'): 0.5420904090770085,\n",
       " ('NULL', 'vas-y'): 0.26523024662679795,\n",
       " ('go', 'vas-y'): 0.13436372785235862,\n",
       " ('now', 'vas-y'): 0.3018860977327299,\n",
       " ('.', 'vas-y'): 0.13648009382127513,\n",
       " ('NULL', 'pigé'): 0.31770020335258964,\n",
       " ('got', \"j'ai\"): 0.679182680871091,\n",
       " ('got', 'pigé'): 0.6013411558953883,\n",
       " ('got', '!'): 0.997225466562922,\n",
       " ('it', \"j'ai\"): 0.560914589810152,\n",
       " ('it', 'pigé'): 0.5487261970931809,\n",
       " ('it', '!'): 0.6423495401552222,\n",
       " ('!', 'pigé'): 0.7267893706335761,\n",
       " ('NULL', 'compris'): 0.6158135395184953,\n",
       " ('got', 'compris'): 0.5885000649730712,\n",
       " ('it', 'compris'): 0.6050043134902023,\n",
       " ('!', 'compris'): 0.35478546069796135,\n",
       " ('got', '?'): 0.7773819946285142,\n",
       " ('it?', 'pigé'): 0.6046033142332834,\n",
       " ('it?', '?'): 0.3092307714734772,\n",
       " ('it?', 'compris'): 0.2456309985441607,\n",
       " ('NULL', \"t'as\"): 0.07126598409496776,\n",
       " ('NULL', 'capté'): 0.3477291676671326,\n",
       " ('got', \"t'as\"): 0.012848073980403552,\n",
       " ('got', 'capté'): 0.16564182663829652,\n",
       " ('it?', \"t'as\"): 0.06036643241777773,\n",
       " ('it?', 'capté'): 0.27815593388711646,\n",
       " ('NULL', 'monte'): 0.3483319943390111,\n",
       " ('hop', 'monte'): 0.5912223113896565,\n",
       " ('hop', '.'): 0.7750131300361086,\n",
       " ('in', 'monte'): 0.6247544671623864,\n",
       " ('in', '.'): 0.1596809333223338,\n",
       " ('.', 'monte'): 0.8937626532322869,\n",
       " ('NULL', 'montez'): 0.7305912660067021,\n",
       " ('hop', 'montez'): 0.4977680192642012,\n",
       " ('in', 'montez'): 0.6436402193909941,\n",
       " ('.', 'montez'): 0.5094750943074225,\n",
       " ('NULL', 'serre-moi'): 0.16820815801861322,\n",
       " ('NULL', 'dans'): 0.6414647725378317,\n",
       " ('NULL', 'tes'): 0.9881677629628269,\n",
       " ('NULL', 'bras'): 0.7703293631175915,\n",
       " ('hug', 'serre-moi'): 0.1814812091194561,\n",
       " ('hug', 'dans'): 0.11976902075848306,\n",
       " ('hug', 'tes'): 0.9303418429877427,\n",
       " ('hug', 'bras'): 0.9100974329622917,\n",
       " ('hug', '!'): 0.7491846596104321,\n",
       " ('me', 'serre-moi'): 0.7605315404167414,\n",
       " ('me', 'dans'): 0.1428757978793307,\n",
       " ('me', 'tes'): 0.8119441915574244,\n",
       " ('me', 'bras'): 0.19227929577547498,\n",
       " ('me', '!'): 0.1547451095413378,\n",
       " ('.', 'serre-moi'): 0.40707895652146964,\n",
       " ('.', 'dans'): 0.00038289436747096506,\n",
       " ('.', 'tes'): 0.8455178161638098,\n",
       " ('.', 'bras'): 0.16113245334394066,\n",
       " ('NULL', 'serrez-moi'): 0.7392507348926605,\n",
       " ('NULL', 'vos'): 0.5829108159234136,\n",
       " ('hug', 'serrez-moi'): 0.7702600029714611,\n",
       " ('hug', 'vos'): 0.599993166737686,\n",
       " ('me', 'serrez-moi'): 0.961467485846172,\n",
       " ('me', 'vos'): 0.3797783894182173,\n",
       " ('.', 'serrez-moi'): 0.4970103500750551,\n",
       " ('.', 'vos'): 0.33833864897286325,\n",
       " ('NULL', 'suis'): 0.7427507415175312,\n",
       " ('NULL', 'tombée'): 0.30049586977343923,\n",
       " ('i', 'suis'): 0.7987862745666682,\n",
       " ('i', 'tombée'): 0.0859497793298083,\n",
       " ('fell', 'je'): 0.23566363766517262,\n",
       " ('fell', 'suis'): 0.4381688926061602,\n",
       " ('fell', 'tombée'): 0.1260458531287345,\n",
       " ('fell', '.'): 0.2030319807878168,\n",
       " ('.', 'suis'): 0.8415427418631352,\n",
       " ('.', 'tombée'): 0.37243245491648513,\n",
       " ('NULL', 'tombé'): 0.2186817294576564,\n",
       " ('i', 'tombé'): 0.8461328224507653,\n",
       " ('fell', 'tombé'): 0.5753746650591521,\n",
       " ('.', 'tombé'): 0.6337164772906705,\n",
       " ('NULL', 'sais'): 0.8889285436761162,\n",
       " ('i', 'sais'): 0.7139590589682182,\n",
       " ('know', 'je'): 0.2651126682511451,\n",
       " ('know', 'sais'): 0.009708308333148619,\n",
       " ('know', '.'): 0.5494634595289904,\n",
       " ('.', 'sais'): 0.7075262252919963,\n",
       " ('NULL', 'parti'): 0.805694609640023,\n",
       " ('i', 'parti'): 0.1906563341982922,\n",
       " ('left', 'je'): 0.6342142760246358,\n",
       " ('left', 'suis'): 0.9385529341093901,\n",
       " ('left', 'parti'): 0.2581863842453116,\n",
       " ('left', '.'): 0.2924804596307673,\n",
       " ('.', 'parti'): 0.4256440120392254,\n",
       " ('NULL', 'partie'): 0.5711786015957309,\n",
       " ('i', 'partie'): 0.9900555533230705,\n",
       " ('left', 'partie'): 0.5881996127046236,\n",
       " ('.', 'partie'): 0.8878993969629735,\n",
       " ('NULL', 'perdu'): 0.6562112790440648,\n",
       " ('i', 'perdu'): 0.47277887411000685,\n",
       " ('lost', \"j'ai\"): 0.30554852972650537,\n",
       " ('lost', 'perdu'): 0.3501795780966964,\n",
       " ('lost', '.'): 0.77713429224723,\n",
       " ('.', \"j'ai\"): 0.17750904732011363,\n",
       " ('.', 'perdu'): 0.13793535839611237,\n",
       " ('NULL', 'payé'): 0.21304496429445163,\n",
       " ('i', 'payé'): 0.6689134401421514,\n",
       " ('paid', 'j’ai'): 0.3714049470154468,\n",
       " ('paid', 'payé'): 0.20650267858283067,\n",
       " ('paid', '.'): 0.3307044032080019,\n",
       " ('.', 'payé'): 0.08162956241513852,\n",
       " ('NULL', '19'): 0.436535553469772,\n",
       " ('NULL', 'ans'): 0.8112159825331954,\n",
       " (\"i'm\", \"j'ai\"): 0.4457924611906908,\n",
       " (\"i'm\", '19'): 0.4473101539932597,\n",
       " (\"i'm\", 'ans'): 0.027528463477695997,\n",
       " (\"i'm\", '.'): 0.2789776720743462,\n",
       " ('19', \"j'ai\"): 0.07517049988664237,\n",
       " ('19', '19'): 0.047738377113599184,\n",
       " ('19', 'ans'): 0.86358557985111,\n",
       " ('19', '.'): 0.714317590312161,\n",
       " ('.', '19'): 0.8304377003762411,\n",
       " ('.', 'ans'): 0.13290579639419553,\n",
       " ('NULL', 'vais'): 0.36528645954502703,\n",
       " ('NULL', 'bien'): 0.913217542315818,\n",
       " (\"i'm\", 'je'): 0.4333878909876069,\n",
       " (\"i'm\", 'vais'): 0.9256518130836788,\n",
       " (\"i'm\", 'bien'): 0.9613680761314508,\n",
       " ('ok', 'je'): 0.006608107989574563,\n",
       " ('ok', 'vais'): 0.4329305855133808,\n",
       " ('ok', 'bien'): 0.5831126288435887,\n",
       " ('ok', '.'): 0.34882757222309646,\n",
       " ('.', 'vais'): 0.3760320179047961,\n",
       " ('.', 'bien'): 0.3558215761577984,\n",
       " (\"i'm\", 'ça'): 0.2310328751730122,\n",
       " (\"i'm\", 'va'): 0.026037244426359463,\n",
       " ('ok', 'ça'): 0.7311839998682425,\n",
       " ('ok', 'va'): 0.9985157672628341,\n",
       " ('.', 'ça'): 0.03834193016002463,\n",
       " ('NULL', 'écoutez'): 0.8590982169530527,\n",
       " ('listen', 'écoutez'): 0.5443049309704545,\n",
       " ('listen', '!'): 0.019519958823183248,\n",
       " ('.', 'écoutez'): 0.06881640857365579,\n",
       " ('NULL', \"c'est\"): 0.5254494810774902,\n",
       " ('NULL', 'pas'): 0.1045602064421326,\n",
       " ('NULL', 'possible'): 0.2959974276602575,\n",
       " ('no', \"c'est\"): 0.27483440401180403,\n",
       " ('no', 'pas'): 0.9706057075617612,\n",
       " ('no', 'possible'): 0.4696664849381693,\n",
       " ('way', \"c'est\"): 0.28518106427047496,\n",
       " ('way', 'pas'): 0.9382420933421521,\n",
       " ('way', 'possible'): 0.9667266688364797,\n",
       " ('way', '!'): 0.7193998828358722,\n",
       " ('!', \"c'est\"): 0.1368790323208824,\n",
       " ('!', 'pas'): 0.8898989854429452,\n",
       " ('!', 'possible'): 0.44126029355469865,\n",
       " ('NULL', 'impossible'): 0.7861273781970614,\n",
       " ('no', 'impossible'): 0.7214887283519693,\n",
       " ('way', 'impossible'): 0.6531640777505399,\n",
       " ('!', 'impossible'): 0.7669731326309766,\n",
       " ('NULL', 'en'): 0.8118302554393781,\n",
       " ('NULL', 'aucun'): 0.4616615406840934,\n",
       " ('NULL', 'cas'): 0.48462060798629536,\n",
       " ('no', 'en'): 0.09738624473422608,\n",
       " ('no', 'aucun'): 0.3708627664523175,\n",
       " ('no', 'cas'): 0.8861342928279523,\n",
       " ('no', '.'): 0.22027202611951346,\n",
       " ('way', 'en'): 0.7489151191794551,\n",
       " ('way', 'aucun'): 0.8066296651536666,\n",
       " ('way', 'cas'): 0.19656782979436171,\n",
       " ('way', '.'): 0.7646026501940553,\n",
       " ('!', 'en'): 0.6573462627480451,\n",
       " ('!', 'aucun'): 0.9754592111041408,\n",
       " ('!', 'cas'): 0.38829314965345374,\n",
       " ('!', '.'): 0.756749996221688,\n",
       " ('NULL', 'sans'): 0.8439536221560057,\n",
       " ('NULL', 'façons'): 0.37907264280754116,\n",
       " ('no', 'sans'): 0.2236880773986134,\n",
       " ('no', 'façons'): 0.3682424018259176,\n",
       " ('way', 'sans'): 0.6528298804275758,\n",
       " ('way', 'façons'): 0.2573873511452943,\n",
       " ('!', 'sans'): 0.8584989326905194,\n",
       " ('!', 'façons'): 0.2951914804582486,\n",
       " ('NULL', 'hors'): 0.7640346656612197,\n",
       " ('NULL', 'de'): 0.3210437359855205,\n",
       " ('NULL', 'question'): 0.5043224141263659,\n",
       " ('no', 'hors'): 0.8741837203856632,\n",
       " ('no', 'de'): 0.48539667306752987,\n",
       " ('no', 'question'): 0.6241885124530137,\n",
       " ('way', 'hors'): 0.3428080361137673,\n",
       " ('way', 'de'): 0.4685735027875845,\n",
       " ('way', 'question'): 0.061414021493359505,\n",
       " ('!', 'hors'): 0.5197664884520465,\n",
       " ('!', 'de'): 0.4491541446297965,\n",
       " ('!', 'question'): 0.29898286145862574,\n",
       " ('NULL', 'il'): 0.17287710693361957,\n",
       " ('NULL', \"n'en\"): 0.3406637209165282,\n",
       " ('NULL', 'est'): 0.29485052230878517,\n",
       " ('no', 'il'): 0.3625376958201626,\n",
       " ('no', \"n'en\"): 0.8087540609599789,\n",
       " ('no', 'est'): 0.8955995601408931,\n",
       " ('way', 'il'): 0.915033322422577,\n",
       " ('way', \"n'en\"): 0.4215556209897613,\n",
       " ('way', 'est'): 0.8984475119819726,\n",
       " ('!', 'il'): 0.5870775927218113,\n",
       " ('!', \"n'en\"): 0.9966110999167729,\n",
       " ('!', 'est'): 0.12426283961828377,\n",
       " ('NULL', 'exclu'): 0.7568315587776803,\n",
       " ('no', 'exclu'): 0.5882685699028393,\n",
       " ('way', 'exclu'): 0.5145660203091754,\n",
       " ('!', 'exclu'): 0.7582155945995201,\n",
       " ('NULL', 'aucune'): 0.8332817242174076,\n",
       " ('NULL', 'manière'): 0.8310878277385972,\n",
       " ('no', 'aucune'): 0.34411893928019344,\n",
       " ('no', 'manière'): 0.38067705732339263,\n",
       " ('way', 'aucune'): 0.5952851275298433,\n",
       " ('way', 'manière'): 0.04287194516336823,\n",
       " ('!', 'aucune'): 0.8147052771678095,\n",
       " ('!', 'manière'): 0.5860231012050868,\n",
       " ('NULL', 'vraiment'): 0.443504721482604,\n",
       " ('really?', 'vraiment'): 0.6381348746177439,\n",
       " ('really?', '?'): 0.9553515775390413,\n",
       " ('NULL', 'vrai'): 0.8042111501038745,\n",
       " ('really?', 'vrai'): 0.6561496917280327,\n",
       " ('NULL', 'ah'): 0.20754234112530112,\n",
       " ('NULL', 'bon'): 0.9717360181200004,\n",
       " ('really?', 'ah'): 0.38711374679552535,\n",
       " ('really?', 'bon'): 0.9052363086662365,\n",
       " ('thanks', 'merci'): 0.5010546237998759,\n",
       " ('thanks', '!'): 0.6724082824575307,\n",
       " ('.', 'merci'): 0.8874029722158654,\n",
       " ('NULL', 'on'): 0.058385754783147226,\n",
       " ('NULL', 'essaye'): 0.2947466449489732,\n",
       " ('we', 'on'): 0.177693587280222,\n",
       " ('we', 'essaye'): 0.046565623732697126,\n",
       " ('we', '.'): 0.3418082807706124,\n",
       " ('try', 'on'): 0.9154007348491935,\n",
       " ('try', 'essaye'): 0.252716278752683,\n",
       " ('.', 'on'): 0.11303781858891349,\n",
       " ('.', 'essaye'): 0.9418449367718151,\n",
       " ('NULL', 'nous'): 0.49331099051249694,\n",
       " ('NULL', 'avons'): 0.4717910210361883,\n",
       " ('we', 'nous'): 0.6878467561330038,\n",
       " ('we', 'avons'): 0.8170848276554661,\n",
       " ('we', 'gagné'): 0.22690730721217645,\n",
       " ('won', 'nous'): 0.20235285442910822,\n",
       " ('won', 'avons'): 0.4244987807759587,\n",
       " ('.', 'nous'): 0.8475929486783617,\n",
       " ('.', 'avons'): 0.9271214033544182,\n",
       " ('NULL', 'gagnâmes'): 0.19040336327223983,\n",
       " ('we', 'gagnâmes'): 0.6894592060239353,\n",
       " ('won', 'gagnâmes'): 0.4458686799115267,\n",
       " ('.', 'gagnâmes'): 0.8781102797423763,\n",
       " ('NULL', \"l'avons\"): 0.2956111011730682,\n",
       " ('we', \"l'avons\"): 0.27020384847136114,\n",
       " ('we', 'emporté'): 0.021931894908752914,\n",
       " ('won', \"l'avons\"): 0.8713508804839094,\n",
       " ('.', \"l'avons\"): 0.16605977983615405,\n",
       " ('.', 'emporté'): 0.27853119786035485,\n",
       " ('NULL', \"l'emportâmes\"): 0.24633119610449994,\n",
       " ('we', \"l'emportâmes\"): 0.9220521803674396,\n",
       " ('won', \"l'emportâmes\"): 0.08162815976425408,\n",
       " ('.', \"l'emportâmes\"): 0.33665844471041073,\n",
       " ('NULL', 'demande'): 0.6804350314668173,\n",
       " ('NULL', 'tom'): 0.16556515600327382,\n",
       " ('ask', 'demande'): 0.5776585047527149,\n",
       " ('ask', 'à'): 0.42465707981586154,\n",
       " ('ask', 'tom'): 0.013140081523351776,\n",
       " ('ask', '.'): 0.6066028879772036,\n",
       " ('tom', 'demande'): 0.3469168821812806,\n",
       " ('tom', 'à'): 0.21152689505945843,\n",
       " ('tom', 'tom'): 0.975150028727401,\n",
       " ('tom', '.'): 0.8389822105081447,\n",
       " ('.', 'demande'): 0.44870930890674976,\n",
       " ('.', 'à'): 0.3212490423026746,\n",
       " ('.', 'tom'): 0.014097884116019754,\n",
       " ('NULL', 'fantastique'): 0.7280698421857733,\n",
       " ('awesome', 'fantastique'): 0.26632354982668927,\n",
       " ('awesome', '!'): 0.5116899525735095,\n",
       " ('!', 'fantastique'): 0.6260190715120957,\n",
       " ('NULL', 'sois'): 0.7529059938083902,\n",
       " ('NULL', 'calme'): 0.15814617408626652,\n",
       " ('be', 'sois'): 0.09131661156147974,\n",
       " ('be', 'calme'): 0.7740671493923287,\n",
       " ('be', '!'): 0.051457931533825385,\n",
       " ('calm', 'sois'): 0.4066173259678242,\n",
       " ('calm', 'calme'): 0.03602349506840796,\n",
       " ('calm', '!'): 0.20778884719084,\n",
       " ('.', 'sois'): 0.18939770163401382,\n",
       " ('.', 'calme'): 0.8399008217165376,\n",
       " ('NULL', 'soyez'): 0.742941723285633,\n",
       " ('be', 'soyez'): 0.24467622059424887,\n",
       " ('calm', 'soyez'): 0.5861680949531992,\n",
       " ('.', 'soyez'): 0.49459881233681513,\n",
       " ('NULL', 'calmes'): 0.09116169080056102,\n",
       " ('be', 'calmes'): 0.3578175734883817,\n",
       " ('calm', 'calmes'): 0.7507009864882975,\n",
       " ('.', 'calmes'): 0.1287675352661406,\n",
       " ('NULL', 'détendu'): 0.23990068029797773,\n",
       " ('be', 'détendu'): 0.3564244417945589,\n",
       " ('cool', 'sois'): 0.004021782407716112,\n",
       " ('cool', 'détendu'): 0.7734535179753902,\n",
       " ('cool', '!'): 0.39509182980869473,\n",
       " ('.', 'détendu'): 0.6386667019464843,\n",
       " ('NULL', 'juste'): 0.5260342792060805,\n",
       " ('be', 'juste'): 0.7793678982934826,\n",
       " ('fair', 'sois'): 0.6588451837938138,\n",
       " ('fair', 'juste'): 0.39875712332682633,\n",
       " ('fair', '!'): 0.1236616225165289,\n",
       " ('.', 'juste'): 0.4240061663628677,\n",
       " ('fair', 'soyez'): 0.005287650017404277,\n",
       " ('NULL', 'justes'): 0.07816590847055904,\n",
       " ('be', 'justes'): 0.829808402863943,\n",
       " ('fair', 'justes'): 0.5167691661110141,\n",
       " ('.', 'justes'): 0.788944895790029,\n",
       " ('NULL', 'équitable'): 0.7391109057664793,\n",
       " ('be', 'équitable'): 0.5277993576896584,\n",
       " ('fair', 'équitable'): 0.7272954759517709,\n",
       " ('.', 'équitable'): 0.943822912511179,\n",
       " ('NULL', 'équitables'): 0.9484260912305764,\n",
       " ('be', 'équitables'): 0.25443145441429216,\n",
       " ('fair', 'équitables'): 0.9083838797223394,\n",
       " ('.', 'équitables'): 0.4710257124637389,\n",
       " ('NULL', 'gentil'): 0.2083833139929948,\n",
       " ('be', 'gentil'): 0.41014770059459915,\n",
       " ('be', '.'): 0.5839311165207918,\n",
       " ('kind', 'sois'): 0.8889993554420076,\n",
       " ('kind', 'gentil'): 0.903374234226432,\n",
       " ('kind', '.'): 0.5597753752415349,\n",
       " ('.', 'gentil'): 0.8071614872922298,\n",
       " ('nice', 'sois'): 0.5291153595962532,\n",
       " ('nice', 'gentil'): 0.09507706410043781,\n",
       " ('nice', '!'): 0.43573865057021555,\n",
       " ('NULL', 'gentille'): 0.6991663706733698,\n",
       " ('be', 'gentille'): 0.7545476523045006,\n",
       " ('nice', 'gentille'): 0.67785352435856,\n",
       " ('.', 'gentille'): 0.002104848701460993,\n",
       " ('nice', 'soyez'): 0.6823374728362215,\n",
       " ('NULL', 'gentils'): 0.9800212481483483,\n",
       " ('be', 'gentils'): 0.21300386173336205,\n",
       " ('nice', 'gentils'): 0.7132169896084609,\n",
       " ('.', 'gentils'): 0.19768911719883886,\n",
       " ('NULL', 'gentilles'): 0.7664892895181451,\n",
       " ('be', 'gentilles'): 0.9357969561592147,\n",
       " ('nice', 'gentilles'): 0.20820116627245155,\n",
       " ('.', 'gentilles'): 0.829340621289375,\n",
       " ('NULL', 'dégage'): 0.2992536353491866,\n",
       " ('beat', 'dégage'): 0.8807049995923031,\n",
       " ('beat', '!'): 0.03177488747995427,\n",
       " ('it', 'dégage'): 0.7552307097680161,\n",
       " ('.', 'dégage'): 0.21536179960192492,\n",
       " ('NULL', 'appelle-moi'): 0.3668869436420428,\n",
       " ('call', 'appelle-moi'): 0.15770894776201927,\n",
       " ('call', '!'): 0.8074310226172426,\n",
       " ('me', 'appelle-moi'): 0.2010538597345054,\n",
       " ('.', 'appelle-moi'): 0.3545788906713093,\n",
       " ('NULL', 'appellez-moi'): 0.365597760057475,\n",
       " ('call', 'appellez-moi'): 0.2675229041664744,\n",
       " ('me', 'appellez-moi'): 0.22392262062458868,\n",
       " ('.', 'appellez-moi'): 0.7476101281451273,\n",
       " ('NULL', 'appelle-nous'): 0.5773827155992554,\n",
       " ('call', 'appelle-nous'): 0.7738629792084443,\n",
       " ('us', 'appelle-nous'): 0.15695556248956266,\n",
       " ('us', '!'): 0.5450644413785326,\n",
       " ('.', 'appelle-nous'): 0.079705132066611,\n",
       " ('NULL', 'appelez-nous'): 0.09841149553940587,\n",
       " ('call', 'appelez-nous'): 0.43197226237138797,\n",
       " ('us', 'appelez-nous'): 0.592249845860918,\n",
       " ('.', 'appelez-nous'): 0.7166423945633572,\n",
       " ('NULL', 'entrez'): 0.5682886008526806,\n",
       " ('come', 'entrez'): 0.0770507900942935,\n",
       " ('come', '!'): 0.3768962543863842,\n",
       " ('in', 'entrez'): 0.7379274286622641,\n",
       " ('in', '!'): 0.9505511854343067,\n",
       " ('.', 'entrez'): 0.9053266060170487,\n",
       " ('NULL', 'entre'): 0.4915903034837521,\n",
       " ('come', 'entre'): 0.9355260853260619,\n",
       " ('come', '.'): 0.25138327823283846,\n",
       " ('in', 'entre'): 0.6169181474195014,\n",
       " ('.', 'entre'): 0.7628187096958498,\n",
       " ('NULL', 'allez'): 0.0016787689092433444,\n",
       " ('come', 'allez'): 0.08212009040304313,\n",
       " ('on', 'allez'): 0.3211789088764324,\n",
       " ('on', '!'): 0.21634980393293957,\n",
       " ('!', 'allez'): 0.17475749052605716,\n",
       " ('.', 'allez'): 0.551840425946582,\n",
       " ('NULL', 'viens'): 0.6396287112027514,\n",
       " ('come', 'viens'): 0.4850272468756095,\n",
       " ('on', 'viens'): 0.6995586797138039,\n",
       " ('.', 'viens'): 0.3181689154948444,\n",
       " ('NULL', 'venez'): 0.3659709824290286,\n",
       " ('come', 'venez'): 0.13299612306597275,\n",
       " ('on', 'venez'): 0.2169440102673399,\n",
       " ('.', 'venez'): 0.4868145261054423,\n",
       " ('NULL', 'laisse'): 0.8264051782292202,\n",
       " ('NULL', 'tomber'): 0.47355178063941394,\n",
       " ('drop', 'laisse'): 0.8831765820246615,\n",
       " ('drop', 'tomber'): 0.9369671393067434,\n",
       " ('drop', '!'): 0.7714579192326468,\n",
       " ('it', 'laisse'): 0.7790135349519337,\n",
       " ('it', 'tomber'): 0.01464380310050073,\n",
       " ('!', 'laisse'): 0.6928559486659069,\n",
       " ('!', 'tomber'): 0.034320365271447884,\n",
       " ('NULL', 'laissez'): 0.7548746057554171,\n",
       " ('drop', 'laissez'): 0.42493001700421396,\n",
       " ('it', 'laissez'): 0.08364082849284105,\n",
       " ('!', 'laissez'): 0.9304388753250722,\n",
       " ('NULL', 'laisse-le'): 0.18520717928212693,\n",
       " ('drop', 'laisse-le'): 0.9603849033875318,\n",
       " ('it', 'laisse-le'): 0.7840689877825939,\n",
       " ('!', 'laisse-le'): 0.9226937236816897,\n",
       " ('NULL', 'laissez-le'): 0.6260065958254272,\n",
       " ('drop', 'laissez-le'): 0.3517796032589069,\n",
       " ('it', 'laissez-le'): 0.69912090821147,\n",
       " ('!', 'laissez-le'): 0.46048584270485193,\n",
       " ('NULL', 'chercher'): 0.7346345269796897,\n",
       " ('get', 'va'): 0.9537510175312837,\n",
       " ('get', 'chercher'): 0.05674264812504226,\n",
       " ('get', 'tom'): 0.16555631776981028,\n",
       " ('tom', 'va'): 0.4303582175138023,\n",
       " ('tom', 'chercher'): 0.027448514864242823,\n",
       " ('.', 'chercher'): 0.3596028234339862,\n",
       " ('NULL', 'sortez'): 0.4231780436580066,\n",
       " ('get', 'sortez'): 0.17452871626694177,\n",
       " ('get', '!'): 0.04198823377757621,\n",
       " ('out', 'sortez'): 0.6350958756290459,\n",
       " ('out', '!'): 0.23701044259636284,\n",
       " ('!', 'sortez'): 0.7000004078324299,\n",
       " ('NULL', 'sors'): 0.41680600086337827,\n",
       " ('get', 'sors'): 0.898063631580873,\n",
       " ('out', 'sors'): 0.29788512683842994,\n",
       " ('!', 'sors'): 0.5407770785563972,\n",
       " ('out', '.'): 0.2849945604401376,\n",
       " ('.', 'sors'): 0.9485777249222824,\n",
       " ('NULL', 'casse-toi'): 0.27776782917302856,\n",
       " ('get', 'casse-toi'): 0.6762385286612236,\n",
       " ('out', 'casse-toi'): 0.354365362528401,\n",
       " ('.', 'casse-toi'): 0.6834897200933504,\n",
       " ('go', 'dégage'): 0.6198783133849382,\n",
       " ('away', 'dégage'): 0.7729925150818439,\n",
       " ('away', '!'): 0.6262507292301286,\n",
       " ('!', 'dégage'): 0.45610056789760844,\n",
       " ('NULL', 'pars'): 0.4505720146485206,\n",
       " ('go', 'pars'): 0.15635950597639103,\n",
       " ('away', 'pars'): 0.11755810682133061,\n",
       " ('!', 'pars'): 0.15474598471370005,\n",
       " ('NULL', 'te'): 0.9295333096696448,\n",
       " ('NULL', 'faire'): 0.670457969514708,\n",
       " ('NULL', 'foutre'): 0.9048610107099665,\n",
       " ('go', 'te'): 0.6146949375583336,\n",
       " ('go', 'faire'): 0.21281212452735265,\n",
       " ('go', 'foutre'): 0.012508678515450677,\n",
       " ('away', 'va'): 0.5336786787627776,\n",
       " ('away', 'te'): 0.9729953582373042,\n",
       " ('away', 'faire'): 0.7936977487574749,\n",
       " ('away', 'foutre'): 0.0689255832829494,\n",
       " ('.', 'te'): 0.36392270604578014,\n",
       " ('.', 'faire'): 0.13339466388959376,\n",
       " ('.', 'foutre'): 0.2704180961487477,\n",
       " ('.', 'pars'): 0.6776194513616779,\n",
       " ('NULL', 'fous'): 0.32564728855856995,\n",
       " ('NULL', 'le'): 0.5094472542632426,\n",
       " ('NULL', 'camp'): 0.28925011327692696,\n",
       " ('go', 'fous'): 0.4096824249368033,\n",
       " ('go', 'le'): 0.3778255596902663,\n",
       " ('go', 'camp'): 0.5834185382368494,\n",
       " ('away', 'fous'): 0.07894453728685369,\n",
       " ('away', 'le'): 0.9936109278764425,\n",
       " ('away', 'camp'): 0.1357349237370119,\n",
       " ('.', 'fous'): 0.05381591084377613,\n",
       " ('.', 'le'): 0.9100306297374963,\n",
       " ('.', 'camp'): 0.3651288379915032,\n",
       " ('NULL', \"d'ici\"): 0.004473425495092775,\n",
       " ('go', \"d'ici\"): 0.2508696810371144,\n",
       " ('away', \"d'ici\"): 0.8083413089981617,\n",
       " ('away', '.'): 0.7428193025084376,\n",
       " ('.', \"d'ici\"): 0.6451438661286618,\n",
       " ('NULL', \"t'en\"): 0.8256441520619726,\n",
       " ('go', \"t'en\"): 0.47282536523659213,\n",
       " ('away', \"t'en\"): 0.9189020672089847,\n",
       " ('.', \"t'en\"): 0.26965340965085405,\n",
       " ('NULL', 'disparais'): 0.4966450735670228,\n",
       " ('go', 'disparais'): 0.8293798606234255,\n",
       " ('away', 'disparais'): 0.5438484300170655,\n",
       " ('.', 'disparais'): 0.2398420584422679,\n",
       " ('NULL', 'allez-vous'): 0.3336523049437071,\n",
       " ('go', 'allez-vous'): 0.860530646521499,\n",
       " ('go', 'en'): 0.5289953018157814,\n",
       " ('away', 'allez-vous'): 0.345771060282964,\n",
       " ('away', 'en'): 0.6240206539638866,\n",
       " ('.', 'allez-vous'): 0.14801202939785696,\n",
       " ('.', 'en'): 0.7413745227105512,\n",
       " ('NULL', 'rentrez'): 0.36387694191834263,\n",
       " ('NULL', 'la'): 0.516729480885077,\n",
       " ('NULL', 'maison'): 0.34666795923760263,\n",
       " ('go', 'rentrez'): 0.8572866175131786,\n",
       " ('go', 'à'): 0.1765346257378747,\n",
       " ('go', 'la'): 0.8691241443899026,\n",
       " ('go', 'maison'): 0.6618477816145172,\n",
       " ('home', 'rentrez'): 0.18157346768852523,\n",
       " ('home', 'à'): 0.1566020782092773,\n",
       " ('home', 'la'): 0.2597315935904744,\n",
       " ('home', 'maison'): 0.44366618015176507,\n",
       " ('home', '.'): 0.9441883604194308,\n",
       " ('.', 'rentrez'): 0.7846037313985447,\n",
       " ('.', 'la'): 0.2880479079839495,\n",
       " ('.', 'maison'): 0.4757061656097876,\n",
       " ('NULL', 'rentre'): 0.04248648746386141,\n",
       " ('go', 'rentre'): 0.7760360643371536,\n",
       " ('home', 'rentre'): 0.7147609067105403,\n",
       " ('.', 'rentre'): 0.6422221935784738,\n",
       " ('NULL', 'chez'): 0.6030270407083584,\n",
       " ('NULL', 'toi'): 0.07450836427174412,\n",
       " ('go', 'chez'): 0.5239796263130855,\n",
       " ('go', 'toi'): 0.6008071170261532,\n",
       " ('home', 'chez'): 0.6193824714887725,\n",
       " ('home', 'toi'): 0.8976475327087362,\n",
       " ('.', 'chez'): 0.33023468096049213,\n",
       " ('.', 'toi'): 0.24427538992874642,\n",
       " ('NULL', 'vous'): 0.4379939989175643,\n",
       " ('go', 'vous'): 0.6172030693534641,\n",
       " ('home', 'vous'): 0.8516159900193536,\n",
       " ('.', 'vous'): 0.7432813413749367,\n",
       " ('NULL', 'doucement'): 0.5176172166644741,\n",
       " ('go', 'doucement'): 0.3896336331226339,\n",
       " ('slow', 'va'): 0.7464423502866897,\n",
       " ('slow', 'doucement'): 0.3706227617705822,\n",
       " ('slow', '!'): 0.4243058042683111,\n",
       " ('.', 'doucement'): 0.018360688779885503,\n",
       " ('go', 'allez'): 0.507761476661556,\n",
       " ('slow', 'allez'): 0.2049473834067983,\n",
       " ('NULL', 'revoyure'): 0.9663490204232643,\n",
       " ('goodbye', 'à'): 0.09247621603517853,\n",
       " ('goodbye', 'la'): 0.04161923211424401,\n",
       " ('goodbye', 'revoyure'): 0.5171031740060944,\n",
       " ('goodbye', '.'): 0.9834575024643463,\n",
       " ('!', 'la'): 0.27394570310953936,\n",
       " ('!', 'revoyure'): 0.1330731668807188,\n",
       " ('NULL', 'un'): 0.09053856705035235,\n",
       " ('NULL', 'peu'): 0.0034843192024166525,\n",
       " ('hang', 'attends'): 0.6157124566561833,\n",
       " ('hang', 'un'): 0.3532369996141904,\n",
       " ('hang', 'peu'): 0.8200075392134119,\n",
       " ('hang', '!'): 0.2216967314652153,\n",
       " ('on', 'attends'): 0.5479999798548296,\n",
       " ('on', 'un'): 0.054397832504823884,\n",
       " ('on', 'peu'): 0.3229010572335552,\n",
       " ('!', 'un'): 0.907536398301619,\n",
       " ('!', 'peu'): 0.6034247947943224,\n",
       " ('hang', 'attendez'): 0.4637392058691132,\n",
       " ('on', 'attendez'): 0.9311566567766025,\n",
       " ('NULL', 'tiens'): 0.3494068092651691,\n",
       " ('hang', 'tiens'): 0.07245871992711317,\n",
       " ('hang', 'bon'): 0.4552456025950534,\n",
       " ('on', 'tiens'): 0.5891385892379942,\n",
       " ('on', 'bon'): 0.7994951298007004,\n",
       " ('.', 'tiens'): 0.3683950162297617,\n",
       " ('.', 'bon'): 0.5197155336357574,\n",
       " ('NULL', 'tenez'): 0.888565801002641,\n",
       " ('hang', 'tenez'): 0.63289997354635,\n",
       " ('on', 'tenez'): 0.2736063538539064,\n",
       " ('.', 'tenez'): 0.9316266340797213,\n",
       " ('NULL', 'laissa'): 0.5697258578046706,\n",
       " ('he', 'il'): 0.8379508782022135,\n",
       " ('he', 'laissa'): 0.8065096483868606,\n",
       " ('he', 'tomber'): 0.671665543334677,\n",
       " ('he', '.'): 0.29893141442208926,\n",
       " ('quit', 'il'): 0.6531284841913282,\n",
       " ('quit', 'laissa'): 0.1153798351096238,\n",
       " ('quit', 'tomber'): 0.669830851054741,\n",
       " ('quit', '.'): 0.525169411981445,\n",
       " ('.', 'il'): 0.3229489310459355,\n",
       " ('.', 'laissa'): 0.4423088971002055,\n",
       " ('.', 'tomber'): 0.285066186711573,\n",
       " ('NULL', 'a'): 0.469911531499571,\n",
       " ('NULL', 'laissé'): 0.4260554552920034,\n",
       " ('he', 'a'): 0.4921874269427836,\n",
       " ('he', 'laissé'): 0.02691424397959108,\n",
       " ('quit', 'a'): 0.10853908530102507,\n",
       " ('quit', 'laissé'): 0.8539070543659134,\n",
       " ('.', 'a'): 0.17579495661911537,\n",
       " ('.', 'laissé'): 0.3106681521529151,\n",
       " ('NULL', 'court'): 0.6956305857365191,\n",
       " ('he', 'court'): 0.384958188369276,\n",
       " ('runs', 'il'): 0.40388964318578835,\n",
       " ('runs', 'court'): 0.03795831312666853,\n",
       " ('runs', '.'): 0.43458502837113466,\n",
       " ('.', 'court'): 0.5707279897347498,\n",
       " ('NULL', 'aide-moi'): 0.4414995470182994,\n",
       " ('help', 'aide-moi'): 0.38159757708112707,\n",
       " ('me', 'aide-moi'): 0.17295868274417758,\n",
       " ('!', 'aide-moi'): 0.38721627575569584,\n",
       " ('help', '.'): 0.050821411691820084,\n",
       " ('me', '.'): 0.2831761150172162,\n",
       " ('.', 'aide-moi'): 0.00836736174477648,\n",
       " ('NULL', 'aidez-moi'): 0.16315087270542838,\n",
       " ('help', 'aidez-moi'): 0.06525159019095506,\n",
       " ('me', 'aidez-moi'): 0.9284498142129368,\n",
       " ('.', 'aidez-moi'): 0.5280542421548592,\n",
       " ('NULL', 'aidez-nous'): 0.2292817385819651,\n",
       " ('help', 'aidez-nous'): 0.6154377060688342,\n",
       " ('us', 'aidez-nous'): 0.26238001783450526,\n",
       " ('.', 'aidez-nous'): 0.6487258817916963,\n",
       " ('NULL', 'aide-nous'): 0.514914512728625,\n",
       " ('help', 'aide-nous'): 0.3960976140942334,\n",
       " ('us', 'aide-nous'): 0.9046790710041067,\n",
       " ('.', 'aide-nous'): 0.6850423123802679,\n",
       " ('NULL', 'ne'): 0.9467980061080153,\n",
       " ('NULL', 'bouge'): 0.2728914032707763,\n",
       " ('NULL', 'plus'): 0.38380729742246933,\n",
       " ('hold', 'ne'): 0.6699393902464338,\n",
       " ('hold', 'bouge'): 0.6227053727434242,\n",
       " ('hold', 'plus'): 0.27182068206906584,\n",
       " ('hold', '!'): 0.09506553295247688,\n",
       " ('it', 'ne'): 0.8285430594432162,\n",
       " ('it', 'bouge'): 0.33911037377693753,\n",
       " ('it', 'plus'): 0.0011729586431145078,\n",
       " ('!', 'ne'): 0.6924072248429248,\n",
       " ('!', 'bouge'): 0.3308248269089814,\n",
       " ('!', 'plus'): 0.7318345170167494,\n",
       " ('NULL', 'quittez'): 0.1201277800211783,\n",
       " ('hold', 'quittez'): 0.2572630224064191,\n",
       " ('hold', 'pas'): 0.9126270364806202,\n",
       " ('hold', '.'): 0.6125529947665633,\n",
       " ('on', 'ne'): 0.40547243153304613,\n",
       " ('on', 'quittez'): 0.8569618394051527,\n",
       " ('on', 'pas'): 0.673018138896365,\n",
       " ('.', 'ne'): 0.17923235727763642,\n",
       " ('.', 'quittez'): 0.2708388285162405,\n",
       " ('.', 'pas'): 0.8805266554458041,\n",
       " ('NULL', 'fais'): 0.936662684692217,\n",
       " ('NULL', 'câlin'): 0.7023209660799887,\n",
       " ('hug', 'fais'): 0.5320698746503908,\n",
       " ('hug', 'un'): 0.9107413297700058,\n",
       " ('hug', 'câlin'): 0.6603435782516186,\n",
       " ('hug', 'à'): 0.9395195146878323,\n",
       " ('hug', 'tom'): 0.7052943963213394,\n",
       " ('hug', '.'): 0.2169852806720648,\n",
       " ('tom', 'fais'): 0.876380620415997,\n",
       " ('tom', 'un'): 0.5350939663224967,\n",
       " ('tom', 'câlin'): 0.3417334115512052,\n",
       " ('.', 'fais'): 0.23267125384165854,\n",
       " ('.', 'un'): 0.27100177153271277,\n",
       " ('.', 'câlin'): 0.5434548861719604,\n",
       " ('NULL', 'du'): 0.04644168367162471,\n",
       " ('NULL', 'même'): 0.3644253356120991,\n",
       " ('NULL', 'avis'): 0.2551816194595856,\n",
       " ('i', 'du'): 0.09723202830178301,\n",
       " ('i', 'même'): 0.5026861837501704,\n",
       " ('i', 'avis'): 0.35577435601739016,\n",
       " ('agree', 'je'): 0.8781816127594143,\n",
       " ('agree', 'suis'): 0.5267167984205586,\n",
       " ('agree', 'du'): 0.14583224239855397,\n",
       " ('agree', 'même'): 0.07745257515133486,\n",
       " ('agree', 'avis'): 0.5686438235684668,\n",
       " ('agree', '.'): 0.7794139981668063,\n",
       " ('.', 'du'): 0.41014106529265293,\n",
       " ('.', 'même'): 0.5347351825867183,\n",
       " ('.', 'avis'): 0.8063800562134763,\n",
       " ('NULL', 'pleuré'): 0.6516679081365223,\n",
       " ('i', 'pleuré'): 0.6073147775796077,\n",
       " ('cried', \"j'ai\"): 0.8936244469416793,\n",
       " ('cried', 'pleuré'): 0.16461459932799738,\n",
       " ('cried', '.'): 0.1727612854006273,\n",
       " ('.', 'pleuré'): 0.94480257306134,\n",
       " ('NULL', 'me'): 0.807278381093218,\n",
       " ('NULL', 'assoupi'): 0.9767607918050952,\n",
       " ('i', 'me'): 0.5258328535793014,\n",
       " ('i', 'assoupi'): 0.4249799770179429,\n",
       " ('dozed', 'je'): 0.9535867812462062,\n",
       " ('dozed', 'me'): 0.62086039561506,\n",
       " ('dozed', 'suis'): 0.4167067942049244,\n",
       " ('dozed', 'assoupi'): 0.43435839625770634,\n",
       " ('dozed', '.'): 0.478791849414424,\n",
       " ('.', 'me'): 0.06032034514385365,\n",
       " ('.', 'assoupi'): 0.1567181939696074,\n",
       " ('NULL', 'assoupie'): 0.6347541392595686,\n",
       " ('i', 'assoupie'): 0.689676476718246,\n",
       " ('dozed', 'assoupie'): 0.8839939229737482,\n",
       " ('.', 'assoupie'): 0.5744348962670367,\n",
       " ('NULL', 'conduis'): 0.14707076358056115,\n",
       " ('i', 'conduis'): 0.6885401626025024,\n",
       " ('drive', 'je'): 0.16133879780538563,\n",
       " ('drive', 'conduis'): 0.531864679929543,\n",
       " ('drive', '.'): 0.20166961609554135,\n",
       " ('.', 'conduis'): 0.27632578830525556,\n",
       " ('NULL', 'fume'): 0.8706149368407702,\n",
       " ('i', 'fume'): 0.5544455257245744,\n",
       " ('smoke', 'je'): 0.7480959677825658,\n",
       " ('smoke', 'fume'): 0.15210084214991826,\n",
       " ('smoke', '.'): 0.4459118626165378,\n",
       " ('.', 'fume'): 0.39243253762578123,\n",
       " ('NULL', 'ronfle'): 0.9767093797164481,\n",
       " ('i', 'ronfle'): 0.7413356955258853,\n",
       " ('snore', 'je'): 0.8230099537383567,\n",
       " ('snore', 'ronfle'): 0.6805352857904879,\n",
       " ('snore', '.'): 0.06710996999705343,\n",
       " ('.', 'ronfle'): 0.7833120801932096,\n",
       " ('NULL', 'pue'): 0.7255433240828253,\n",
       " ('i', 'pue'): 0.6989384801541518,\n",
       " ('stink', 'je'): 0.42770551365492826,\n",
       " ('stink', 'pue'): 0.2724461451950544,\n",
       " ('stink', '.'): 0.4943232215517085,\n",
       " ('.', 'pue'): 0.40604836054880056,\n",
       " ('NULL', 'tenu'): 0.10595217027035497,\n",
       " ('NULL', 'debout'): 0.7725817999279438,\n",
       " ('i', 'tenu'): 0.661929913585452,\n",
       " ('i', 'debout'): 0.15051770724535252,\n",
       " ('stood', 'je'): 0.6130328401424923,\n",
       " ('stood', 'me'): 0.9498286221642943,\n",
       " ('stood', 'suis'): 0.5324771182970127,\n",
       " ('stood', 'tenu'): 0.04486082254784973,\n",
       " ('stood', 'debout'): 0.9670515579196218,\n",
       " ('stood', '.'): 0.6490421742972696,\n",
       " ('.', 'tenu'): 0.4803915784697125,\n",
       " ('.', 'debout'): 0.9533726257754283,\n",
       " ('NULL', 'tenue'): 0.4457848339722408,\n",
       " ('i', 'tenue'): 0.21400799311948215,\n",
       " ('stood', 'tenue'): 0.0036020320578317166,\n",
       " ('.', 'tenue'): 0.7950350648021278,\n",
       " ('NULL', 'promis'): 0.14831211000659306,\n",
       " ('i', 'promis'): 0.796953172076784,\n",
       " ('swore', 'j’ai'): 0.08130788761506391,\n",
       " ('swore', 'promis'): 0.633391776382595,\n",
       " ('swore', '.'): 0.02343763399002574,\n",
       " ('.', 'promis'): 0.720803630275586,\n",
       " ('NULL', 'juré'): 0.014020862597497352,\n",
       " ('i', 'juré'): 0.8967370644602778,\n",
       " ('swore', 'juré'): 0.588065513394617,\n",
       " ('.', 'juré'): 0.7928244989272889,\n",
       " ('NULL', \"j'essayai\"): 0.9239591989883328,\n",
       " ('i', \"j'essayai\"): 0.5783962946695218,\n",
       " ('tried', \"j'essayai\"): 0.5506052399635282,\n",
       " ('tried', '.'): 0.9283359230900097,\n",
       " ('.', \"j'essayai\"): 0.6914748070298812,\n",
       " ('NULL', 'essayé'): 0.7924611326613269,\n",
       " ('i', 'essayé'): 0.5064258057656756,\n",
       " ('tried', \"j'ai\"): 0.9942442530482722,\n",
       " ('tried', 'essayé'): 0.5625639010576898,\n",
       " ('.', 'essayé'): 0.1410200006070247,\n",
       " ('NULL', 'tenté'): 0.0408057088494187,\n",
       " ('i', 'tenté'): 0.841606520149457,\n",
       " ('tried', 'tenté'): 0.09214899523162112,\n",
       " ('.', 'tenté'): 0.586800347453365,\n",
       " ('NULL', 'fait'): 0.4990139655893554,\n",
       " ('NULL', 'signe'): 0.8145775004179531,\n",
       " ('i', 'fait'): 0.369607044598686,\n",
       " ('i', 'signe'): 0.16543323450179637,\n",
       " ('waved', 'j’ai'): 0.17859406824271962,\n",
       " ('waved', 'fait'): 0.11748430799918241,\n",
       " ('waved', 'signe'): 0.5193102305961064,\n",
       " ('waved', '.'): 0.07116801691584573,\n",
       " ('.', 'fait'): 0.4205862884409376,\n",
       " ('.', 'signe'): 0.2306826438092907,\n",
       " ('NULL', \"j'irai\"): 0.14223838984828896,\n",
       " (\"i'll\", \"j'irai\"): 0.7308940335391836,\n",
       " (\"i'll\", '.'): 0.7985299180812585,\n",
       " ('go', \"j'irai\"): 0.7410110958557263,\n",
       " ('.', \"j'irai\"): 0.3946774279364177,\n",
       " (\"i'm\", 'suis'): 0.47387519995384375,\n",
       " (\"i'm\", 'tom'): 0.7190025235632571,\n",
       " ('tom', 'je'): 0.6431235350719433,\n",
       " ('tom', 'suis'): 0.5343663502046756,\n",
       " ('NULL', 'gras'): 0.23958889080118495,\n",
       " (\"i'm\", 'gras'): 0.25138514753378016,\n",
       " ('fat', 'je'): 0.5502558468786566,\n",
       " ('fat', 'suis'): 0.7884872555979374,\n",
       " ('fat', 'gras'): 0.37716484116962967,\n",
       " ('fat', '.'): 0.5628445974107426,\n",
       " ('.', 'gras'): 0.9892459921570295,\n",
       " ('NULL', 'gros'): 0.3562376167505199,\n",
       " (\"i'm\", 'gros'): 0.7934569246976079,\n",
       " ('fat', 'gros'): 0.5858957279846411,\n",
       " ('.', 'gros'): 0.3880539875669605,\n",
       " ('NULL', 'forme'): 0.510086076592842,\n",
       " (\"i'm\", 'en'): 0.06767670770168555,\n",
       " (\"i'm\", 'forme'): 0.5859378936584149,\n",
       " ('fit', 'je'): 0.832535828595315,\n",
       " ('fit', 'suis'): 0.06861852804824053,\n",
       " ('fit', 'en'): 0.6470027864356599,\n",
       " ('fit', 'forme'): 0.05095959821681384,\n",
       " ('fit', '.'): 0.1130721522718422,\n",
       " ('.', 'forme'): 0.6263424068737182,\n",
       " ('NULL', 'touché'): 0.5346838936776972,\n",
       " (\"i'm\", 'touché'): 0.18941713339814015,\n",
       " (\"i'm\", '!'): 0.34416908720754646,\n",
       " ('hit', 'je'): 0.11370262509574625,\n",
       " ('hit', 'suis'): 0.6910715118020734,\n",
       " ('hit', 'touché'): 0.6802856090229452,\n",
       " ('hit', '!'): 0.9621083361673528,\n",
       " ('!', 'suis'): 0.6882414041462181,\n",
       " ('!', 'touché'): 0.9178657232923366,\n",
       " ('NULL', 'touchée'): 0.8027433590624368,\n",
       " (\"i'm\", 'touchée'): 0.5823759539283118,\n",
       " ('hit', 'touchée'): 0.5415008793567033,\n",
       " ('!', 'touchée'): 0.09888758593230496,\n",
       " ('NULL', 'malade'): 0.17256034493741712,\n",
       " (\"i'm\", 'malade'): 0.603596292487155,\n",
       " ('ill', 'je'): 0.3791477519815619,\n",
       " ('ill', 'suis'): 0.11795498928735348,\n",
       " ('ill', 'malade'): 0.809282206434085,\n",
       " ('ill', '.'): 0.3711945389004616,\n",
       " ('.', 'malade'): 0.07115710646801432,\n",
       " ('NULL', 'triste'): 0.10535798433196131,\n",
       " (\"i'm\", 'triste'): 0.05902707762616466,\n",
       " ('sad', 'je'): 0.21720946392545804,\n",
       " ('sad', 'suis'): 0.5536397455628724,\n",
       " ('sad', 'triste'): 0.5032717813255988,\n",
       " ('sad', '.'): 0.20017441357015298,\n",
       " ('.', 'triste'): 0.12673680217235617,\n",
       " ('NULL', 'timide'): 0.4733373832911062,\n",
       " (\"i'm\", 'timide'): 0.6210175512987259,\n",
       " ('shy', 'je'): 0.48906192812475746,\n",
       " ('shy', 'suis'): 0.5080301822006882,\n",
       " ('shy', 'timide'): 0.9199458031922415,\n",
       " ('shy', '.'): 0.8383967176214563,\n",
       " ('.', 'timide'): 0.7475581500157495,\n",
       " ('NULL', 'mouillé'): 0.3962950221540372,\n",
       " (\"i'm\", 'mouillé'): 0.5705873461033832,\n",
       " ('wet', 'je'): 0.7266106273201105,\n",
       " ('wet', 'suis'): 0.43729284544641456,\n",
       " ('wet', 'mouillé'): 0.047169802954657,\n",
       " ('wet', '.'): 0.6657231323325583,\n",
       " ('.', 'mouillé'): 0.8696006841631853,\n",
       " ('NULL', 'mouillée'): 0.3103937293746838,\n",
       " (\"i'm\", 'mouillée'): 0.7905930946436218,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_t = init(list(align_counts.keys()))\n",
    "hard_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_EM(en_sents, fr_sents, fr_vocab, t):\n",
    "    '''\n",
    "    One 'Expectation', 'Maximization' iteration.\n",
    "    params:\n",
    "        en_sents: List[List[str]]\n",
    "        fr_sents: List[List[str]]\n",
    "        fr_vocab: int --- size of the French vocab\n",
    "        t: Dict() --- translation probability dictionary from last iteration\n",
    "        \n",
    "    return:\n",
    "        new_t: Dict() --- updated parameters, dictionary\n",
    "    '''\n",
    "    new_t = t\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    for en_sent, fr_sent in zip(en_sents, fr_sents):\n",
    "        print(en_sent, fr_sent)\n",
    "        break\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### END OF YOUR CODE\n",
    "    \n",
    "    return new_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NULL', 'go', '.'] ['va', '!']\n"
     ]
    }
   ],
   "source": [
    "hard_t = hard_EM(english_sents, french_sents, fr_vocab, hard_t)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in log\n",
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-603016679dfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0miteration\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mlogp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menglish_sents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrench_sents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhard_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mhard_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhard_EM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menglish_sents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrench_sents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfr_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhard_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Objective Function:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-bb30eff85759>\u001b[0m in \u001b[0;36mcorpus_log_prob\u001b[1;34m(en_sents, fr_sents, t)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfr_word\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfr_sent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfr_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfr_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mlogp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0men_word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfr_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# Randomly initialized the probabilities under the contraint\n",
    "############################################################\n",
    "hard_t = init(list(align_counts.keys()))\n",
    "    \n",
    "##################\n",
    "# Hard EM training\n",
    "##################\n",
    "iteration = 0\n",
    "while iteration < 10:\n",
    "    \n",
    "    logp = corpus_log_prob(english_sents, french_sents, hard_t)    \n",
    "    hard_t = hard_EM(english_sents, french_sents, fr_vocab, hard_t)  \n",
    "    print('Objective Function:', round(logp, 5))\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18sBQ---8RRc"
   },
   "source": [
    "### Visualization\n",
    "Using 2D-heatmap, visualize the translation probability (namely $t(f|e)$) for each of the instances below:\n",
    "\n",
    "    NULL tom loves chocolate .   tom adore le chocolat .    \n",
    "    NULL it was a very exciting game .   c'était un jeu vraiment très excitant .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trans_prob(en, fr, t):\n",
    "    '''\n",
    "    Visualize the translation probability of an instance\n",
    "    '''\n",
    "    alignments = np.zeros([len(fr), len(en)])\n",
    "    for i in range(len(fr)):\n",
    "        for j in range(len(en)):\n",
    "            alignments[i, j] = t[(en[j], fr[i])]\n",
    "    sns.heatmap(alignments, cmap='PuBuGn', annot=True)\n",
    "    _, _ = plt.yticks(np.arange(len(fr))+0.5, fr, rotation=0, fontsize=10)\n",
    "    _, _ = plt.xticks(np.arange(len(en))+0.5, en, rotation=30, fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = \"NULL tom loves chocolate .\".split()\n",
    "fr = \"tom adore le chocolat .\".split()\n",
    "visualize_trans_prob(en, fr, hard_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "en = \"NULL it was a very exciting game .\".split()\n",
    "fr = \"c'était un jeu vraiment très excitant .\".split()\n",
    "visualize_trans_prob(en, fr, hard_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azApJ9p78RRd"
   },
   "source": [
    "## Soft EM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUYEBjlO8RRe"
   },
   "source": [
    "### Question 4 (10 points)\n",
    "\n",
    "1. Implement ``soft_EM`` function which runs one ``Expectation/Maximization`` iteration.\n",
    "2. Run the training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_EM(en_sents, fr_sents, t):\n",
    "    '''\n",
    "    params:\n",
    "        en_sents: English sentences, list\n",
    "        fr_sents: foreign sentences, list\n",
    "    return:\n",
    "        t: updated parameters, dictionary\n",
    "    '''\n",
    "    new_t = t\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    ### END OF YOUR CODE\n",
    "    return new_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the algorithm first using the objective value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Randomly initialized the probabilities under the contraint\n",
    "############################################################\n",
    "soft_t = init(list(align_counts.keys()))\n",
    "    \n",
    "##################\n",
    "# Hard EM training\n",
    "##################\n",
    "iteration = 0\n",
    "while iteration < 15:\n",
    "    \n",
    "    logp = corpus_log_prob(english_sents, french_sents, soft_t)    \n",
    "    soft_t = soft_EM(english_sents, french_sents, soft_t)  \n",
    "    print('Objective Function:', round(logp, 5))\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en = \"NULL tom loves chocolate .\".split()\n",
    "fr = \"tom adore le chocolat .\".split()\n",
    "visualize_trans_prob(en, fr, soft_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "en = \"NULL it was a very exciting game .\".split()\n",
    "fr = \"c'était un jeu vraiment très excitant .\".split()\n",
    "visualize_trans_prob(en, fr, soft_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework 3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
